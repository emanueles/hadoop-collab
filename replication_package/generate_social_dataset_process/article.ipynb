{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "#from jira import JIRA\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECTS = ['hadoop', 'hdfs', 'yarn', 'mapreduce']\n",
    "PATH_ORIGINAL_DATASET_FILES = \"original-dataset/\"\n",
    "PATH_SOCIAL_DATASET_FILES = \"social-dataset/\"\n",
    "PATH_GENERATED_FILES = PATH_SOCIAL_DATASET_FILES + \"generated_dataset/\"\n",
    "BOTS_USERNAMES_JIRA = ['githubbot', 'genericqa', 'HadoopDev', 'hadoopqa', 'hudson', 'jiraposter@reviews.apache.org']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------- Utilized classes --------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApacheMember:\n",
    "    def __init__(self, username, name, organization, roles, timezone, pmc, committer):\n",
    "        self.username = username\n",
    "        self.name = name\n",
    "        self.organization = organization\n",
    "        self.roles = roles\n",
    "        self.timezone = timezone\n",
    "        self.pmc = pmc\n",
    "        self.committer = committer\n",
    "\n",
    "    def csv_line(self):\n",
    "        return self.username + ';' + self.name \\\n",
    "               + ';' + str(self.organization) \\\n",
    "               + ';' + str(self.roles) \\\n",
    "               + ';' + str(self.organization) \\\n",
    "               + ';' + str(self.timezone) \\\n",
    "               + ';' + str(self.pmc) \\\n",
    "               + ';' + str(self.committer) + '\\n'\n",
    "\n",
    "def remove_nan_str_pandas(string):\n",
    "    return \"\" if pandas.isnull(string) else str(string)\n",
    "\n",
    "class ContributorInfo():\n",
    "    def __init__(self, id, name_git, username_jira, name_jira):\n",
    "        self.id = id\n",
    "        self.name_git = name_git\n",
    "        self.username_jira = username_jira\n",
    "        self.name_jira = name_jira\n",
    "\n",
    "    def to_csv_line(self):\n",
    "        return remove_nan_str_pandas(self.id) + ';' + remove_nan_str_pandas(self.name_git) + ';' + \\\n",
    "               remove_nan_str_pandas(self.username_jira) + ';' + remove_nan_str_pandas(self.name_jira) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------- Support functions --------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file and return a pandas dataset\n",
    "# type -> snapshot, comment-log, changelog or commit-log\n",
    "def get_info_project_in_dataset(type):\n",
    "    dataset = []\n",
    "    for project in PROJECTS:\n",
    "        dataset.append(\n",
    "            pandas.read_csv(PATH_ORIGINAL_DATASET_FILES + type + \"/\" + project + \"-bug-fix-dataset.csv\", index_col=None, header=0,\n",
    "                                delimiter=';')\n",
    "        )\n",
    "    return pandas.concat(dataset, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate files with of all contributors info\n",
    "def do_mine_contributors_names():\n",
    "    snapshot_dataset = get_info_project_in_dataset(\"snapshot\")\n",
    "\n",
    "    commentlog_dataset = get_info_project_in_dataset(\"comment-log\")\n",
    "\n",
    "    changelog_dataset = get_info_project_in_dataset(\"changelog\")\n",
    "\n",
    "    commitlog_dataset = get_info_project_in_dataset(\"commit-log\")\n",
    "\n",
    "    jira_team_dataset = pandas.DataFrame(columns=['Name'])\n",
    "    git_team_dataset = pandas.DataFrame(columns=['Name'])\n",
    "\n",
    "    jira_team = set()\n",
    "    git_team = set()\n",
    "\n",
    "    for index, row in snapshot_dataset.iterrows():\n",
    "        jira_team.add(row.Reporter)\n",
    "        jira_team.add(row.Assignee)\n",
    "\n",
    "    for index, row in commentlog_dataset.iterrows():\n",
    "        jira_team.add(row.Author)\n",
    "\n",
    "    for index, row in changelog_dataset.iterrows():\n",
    "        jira_team.add(row.Author)\n",
    "\n",
    "    for index, row in commitlog_dataset.iterrows():\n",
    "        git_team.add(row.Author)\n",
    "        git_team.add(row.Committer)\n",
    "\n",
    "    jira_team_dataset = pandas.DataFrame(jira_team)\n",
    "    jira_team_dataset.columns = ['Name']\n",
    "\n",
    "    git_team_dataset = pandas.DataFrame(git_team)\n",
    "    git_team_dataset.columns = ['Name']\n",
    "\n",
    "    jira_team_dataset.to_csv(PATH_SOCIAL_DATASET_FILES + \"jira-community-contributors-names.csv\", sep=';', encoding='utf-8',\n",
    "                             index=False, na_rep='NULL')\n",
    "    git_team_dataset.to_csv(PATH_SOCIAL_DATASET_FILES + \"git-community-contributors-names.csv\", sep=';', encoding='utf-8',\n",
    "                            index=False, na_rep='NULL')\n",
    "\n",
    "    return jira_team_dataset, git_team_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unify jira records that have the same name (create the association Name -> Usernames).\n",
    "def group_by_name_usernames_of_jira(df_jira_usernames=None):\n",
    "    if df_jira_usernames is None:\n",
    "        df_jira_usernames = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"database_user_jira.csv\", index_col=None,\n",
    "                                            header=0, delimiter=';')\n",
    "    mapped = {}\n",
    "    cons = open(PATH_GENERATED_FILES + 'jira_hadoop_users.csv', 'w')\n",
    "    cons.write('username;Name;bot\\n')\n",
    "\n",
    "    count = 1\n",
    "\n",
    "    for index, row in df_jira_usernames.iterrows():\n",
    "        if pandas.isnull(row.Name) or not row.Name or row.Name == '--------':\n",
    "            name = 'Without name - ' + str(count)\n",
    "            count += 1\n",
    "            row.Name = name\n",
    "            mapped[name] = row\n",
    "            continue\n",
    "\n",
    "        if row.Name in mapped.keys():\n",
    "            mapped[row.Name].username += ' | ' + row.username\n",
    "        else:\n",
    "            mapped[row.Name] = row\n",
    "\n",
    "    new_df_jira_usernames = pandas.DataFrame(columns=['Username', 'Name', 'bot'])\n",
    "    for key in mapped.keys():\n",
    "        cons.write(str(mapped[key].username) + ';' + str(mapped[key].Name) + ';' + str(mapped[key].bot) + '\\n')\n",
    "\n",
    "        new_df_jira_usernames = pandas.concat([new_df_jira_usernames, pandas.DataFrame({'Username': str(mapped[key].username),\n",
    "                                            'Name': str(mapped[key].Name), 'bot': mapped[key].bot}, index=[0])], ignore_index=True)\n",
    "\n",
    "    cons.close()\n",
    "\n",
    "    return new_df_jira_usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the info of hadoop member tabs (official contributors): pmc e committers\n",
    "def union_pmc_and_committers_members_file():\n",
    "    # list of contributors taken from the apache website\n",
    "    pmc = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"hadoop-members-10-05-2020_aba_pmc.csv\", index_col=None, header=0,\n",
    "                          delimiter=';')\n",
    "    # manually generated list with information on all contributors who committed to projects\n",
    "    committers = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"hadoop-members-10-05-2020_aba_committers.csv\", index_col=None,\n",
    "                                 header=0, delimiter=';')\n",
    "\n",
    "    df = pandas.DataFrame(columns=['username', 'Name', 'organization', 'roles', 'timezone', 'isPmc', 'isCommitter'])\n",
    "\n",
    "    mapped = {}\n",
    "    cons = open(PATH_SOCIAL_DATASET_FILES + 'hadoop-members-10-05-2020-full.csv', 'w')\n",
    "\n",
    "    cons.write('username;Name;organization;roles;timezone;isPmc;isCommitter')\n",
    "\n",
    "    for index, row in pmc.iterrows():\n",
    "        member = ApacheMember(row.username, row.Name, row.organization, row.roles, row.timezone, True, False)\n",
    "        mapped[row.username] = member\n",
    "\n",
    "    for index, row in committers.iterrows():\n",
    "        if row.username in mapped.keys():\n",
    "            mapped[row.username].committer = True\n",
    "            continue\n",
    "\n",
    "        member = ApacheMember(row.username, row.Name, row.organization, row.roles, row.timezone, False, True)\n",
    "        mapped[row.username] = member\n",
    "\n",
    "    sorted_keys = list(mapped.keys())\n",
    "    for key in sorted_keys:\n",
    "        cons.write(mapped[key].csv_line())\n",
    "        df = pandas.concat([df, pandas.DataFrame({'username': mapped[key].username, 'Name': str(mapped[key].name),\n",
    "                   'organization': str(mapped[key].organization), 'roles': str(mapped[key].roles),\n",
    "                   'timezone': str(mapped[key].timezone), 'isPmc': str(mapped[key].pmc),\n",
    "                   'isCommitter': str(mapped[key].committer)}, index=[0])], ignore_index=True)\n",
    "\n",
    "    cons.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines the list of contributors to the apache webpage with the git contributors\n",
    "def union_hadoop_official_members_with_committers_of_dataset(git_team_dataset, official_committers_hadoop_dataset = None):\n",
    "    if official_committers_hadoop_dataset is None:\n",
    "        official_committers_hadoop_dataset = \\\n",
    "            pandas.read_csv(PATH_SOCIAL_DATASET_FILES + 'hadoop-members-10-05-2020-full.csv', index_col=None,\n",
    "                            header=0, delimiter=';')\n",
    "\n",
    "    committers_and_hadoop_members = official_committers_hadoop_dataset.copy()\n",
    "\n",
    "    shutil.copy(PATH_SOCIAL_DATASET_FILES + 'hadoop-members-10-05-2020-full.csv',\n",
    "                PATH_SOCIAL_DATASET_FILES + 'committers_and_hadoop_members_git.csv')\n",
    "\n",
    "    cons = open(PATH_SOCIAL_DATASET_FILES + 'committers_and_hadoop_members_git.csv', 'a')\n",
    "\n",
    "    committers_of_dataset = set(git_team_dataset['Name'].tolist())\n",
    "    hadoop_members = official_committers_hadoop_dataset['Name'].tolist()\n",
    "\n",
    "    for name in committers_of_dataset:\n",
    "        if name not in hadoop_members:\n",
    "            committers_and_hadoop_members = pandas.concat([committers_and_hadoop_members, pandas.DataFrame({'username': '----', 'Name': name,\n",
    "                                                                                  'organization': '----',\n",
    "                                                                                  'roles': '----',\n",
    "                                                                                  'timezone': '----', 'isPmc': '---',\n",
    "                                                                                  'isCommitter': '--'}, index=[0])],\n",
    "                                                                                 ignore_index=True)\n",
    "\n",
    "            cons.write('----;' + name + ';----;----;----;----;----;----\\n')\n",
    "\n",
    "    cons.close()\n",
    "\n",
    "    return committers_and_hadoop_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join information from git and jira, generating a unique id for each\n",
    "def join_contributors_info():\n",
    "    git = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"4-git_team_after_manual_map.csv\",\n",
    "                          index_col=None, header=0,\n",
    "                          delimiter=';')\n",
    "\n",
    "    jira = pandas.read_csv(PATH_GENERATED_FILES + \"jira_hadoop_users.csv\",\n",
    "                           index_col=None, header=0,\n",
    "                           delimiter=';')\n",
    "\n",
    "    arq = open(PATH_GENERATED_FILES + 'list_of_contributors.csv', 'w')\n",
    "    arq.write(\"id;name_git;username_jira;name_jira\\n\")\n",
    "\n",
    "    count = 1\n",
    "    mapped = {}\n",
    "\n",
    "    for index, row in jira.iterrows():\n",
    "        id = \"id\" + str(count)\n",
    "\n",
    "        info = None\n",
    "\n",
    "        git_register = git[git['Name'].str.contains(str(row.Name), case=False)]\n",
    "        name = ''\n",
    "        if not git_register.empty:\n",
    "            info = ContributorInfo(id, git_register['Name'].iloc[0], row.username, row.Name)\n",
    "            name = git_register['Name'].iloc[0]\n",
    "        else:\n",
    "            info = ContributorInfo(id, '', row.username, row.Name)\n",
    "            name = row.Name\n",
    "\n",
    "        if name in mapped.keys():\n",
    "            name = name + id\n",
    "\n",
    "        mapped[name] = info\n",
    "        count += 1\n",
    "\n",
    "    for index, row in git.iterrows():\n",
    "        if row.Name not in mapped.keys():\n",
    "            id = \"id\" + str(count)\n",
    "            mapped[row.Name] = ContributorInfo(id, row.Name, '', '')\n",
    "            count += 1\n",
    "\n",
    "    for key in mapped.keys():\n",
    "        arq.write(mapped[key].to_csv_line())\n",
    "\n",
    "    arq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual mapping done by the authors in the generated dataset, analyzing all records\n",
    "def get_manual_correction():\n",
    "    git_name = {\n",
    "        \"Owen O'Malley\": \"owen.omalley\",\n",
    "        \"Chris Douglas\": \"chris.douglas\",\n",
    "        \"Christopher Douglas\": \"chris.douglas\",\n",
    "        \"Akira Ajisaka\": \"ajisakaa\",\n",
    "        \"Arun C Murthy, Arun C. Murthy\": \"acmurthy\",\n",
    "        \"Arun Murthy\": \"acmurthy\",\n",
    "        \"Anu Engineer\": \"anu\",\n",
    "        \"Bibin A Chundatt\": \"bibinchundatt\",\n",
    "        \"Billie Rinaldi\": \"billie.rinaldi\",\n",
    "        \"Konstantin Boudnik\": \"cos\",\n",
    "        \"Márton Elek\": \"elek\",\n",
    "        \"Eric Payne, Eric E Payne\": \"eepayne\",\n",
    "        \"He Xiaoqiao\": \"hexiaoqiao\",\n",
    "        \"Lohit Vijaya\": \"renulohit\",\n",
    "        \"Nanda kumar\": \"nandakumar131\",\n",
    "        \"Patrick Hunt\": \"phunt\",\n",
    "        \"Prabhu Joseph\": \"Prabhu Joseph\",\n",
    "        \"Scott Chun-Yang Chen\": \"schen\",\n",
    "        \"Subru Krishnan\": \"subru\",\n",
    "        \"Takanobu Asanuma\": \"tasanuma0829\",\n",
    "        \"Andrew Purtell\": \"apurtell\",\n",
    "        \"Thomas Marquardt\": \"tmarquardt\",\n",
    "        \"Vidura Mudalige\": \"vbmudalige\",\n",
    "        \"Devaraj K, Devarajulu K\": \"devaraj.k\",\n",
    "        'Arpit Agarwal': 'arpitagarwal',\n",
    "        'sanford ryza': 'sandyr',\n",
    "        'Bharat Viswanadham': 'bharatviswa',\n",
    "        # some contributors use username in git\n",
    "        \"bibinchundatt\": \"bibinchundatt\",\n",
    "        \"cnauroth\": 'cnauroth',\n",
    "        #\"yufei\": \"yufei\",\n",
    "        \"sidharta s\": \"sidharta-s\",\n",
    "        \"tgraves\": \"tgraves\",\n",
    "        \"drankye\": \"drankye\",\n",
    "        \"yliu\": \"hitliuyi\",\n",
    "        'arp': 'arpitagarwal',\n",
    "        'rohithsharmaks':'rohithsharma',\n",
    "        'mattf': 'mattf',\n",
    "        'bharat': 'bharatviswa',\n",
    "        'yufei': 'yufeigu',\n",
    "        # adjust for conversion of special characters to lower case\n",
    "        \"vinod kumar vavilapalli (i am also known as @tshooter.)\".lower(): \"vinodkv\"\n",
    "    }\n",
    "\n",
    "    jira_usernames = {}\n",
    "\n",
    "    for key in git_name.keys():\n",
    "        if git_name[key] in jira_usernames.keys():\n",
    "            jira_usernames[git_name[key]] += ', ' + key\n",
    "        else:\n",
    "            jira_usernames[git_name[key]] = key\n",
    "\n",
    "    # wrong association\n",
    "    jira_usernames['rajuvishnu'] = ''\n",
    "    jira_usernames['sohu0011'] = ''\n",
    "    jira_usernames['jsaraiya'] = ''\n",
    "    jira_usernames['azuriel'] = ''\n",
    "    jira_usernames['Fan04290'] = ''\n",
    "    jira_usernames['mgiri935'] = ''\n",
    "    jira_usernames['hom'] = ''\n",
    "    jira_usernames['Xiangyi'] = ''\n",
    "    jira_usernames['abalitsky'] = ''\n",
    "    jira_usernames['lewuathe'] = ''\n",
    "    jira_usernames['rakesh_techie'] = ''\n",
    "\n",
    "    return git_name, jira_usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final procedure for generating the list of contributors\n",
    "def final_processing_info_contributors():\n",
    "    registers = pandas.read_csv(PATH_GENERATED_FILES + \"list_of_contributors.csv\",\n",
    "                           index_col=None, header=0,\n",
    "                           delimiter=';')\n",
    "\n",
    "    git_names_correction, jira_usernames_correction = get_manual_correction()\n",
    "\n",
    "    drop_index = []\n",
    "\n",
    "    for index, row in registers.iterrows():\n",
    "        if row.name_git in git_names_correction.keys():\n",
    "            if pandas.isnull(row.username_jira):\n",
    "                drop_index.append(index)\n",
    "                print('droping: ' + row.name_git)\n",
    "            else:\n",
    "                registers.at[index, 'name_git'] = ''\n",
    "\n",
    "        if row.username_jira in jira_usernames_correction.keys():\n",
    "            if pandas.isnull(row.name_git):\n",
    "                registers.at[index, 'name_git'] = str(jira_usernames_correction[row.username_jira])\n",
    "            else:\n",
    "                registers.at[index, 'name_git'] = '{0}, {1}'.format(row.name_git,\n",
    "                                                                    jira_usernames_correction[row.username_jira])\n",
    "\n",
    "            if jira_usernames_correction[row.username_jira] != '': # A correct association\n",
    "                print('replacing \"{0}\" for \"{1}\"'.format(row.name_git, jira_usernames_correction[row.username_jira]))\n",
    "\n",
    "    registers = registers.drop(drop_index)\n",
    "\n",
    "    registers.to_csv(PATH_GENERATED_FILES + 'final_list_of_contributors.csv', sep=';', encoding='utf-8',\n",
    "                     index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves unique user id based on jira username\n",
    "def get_id_by_username_jira(registers, username):\n",
    "    if pandas.isnull(username):\n",
    "        return '-1'\n",
    "\n",
    "    username = username.strip().lower()\n",
    "\n",
    "    usernames = registers.loc[registers.username_jira.str.contains(str(username), na=False, case=False, regex=False)]\n",
    "\n",
    "    for index, row in usernames.iterrows():\n",
    "        if ' | ' in row.username_jira:\n",
    "            users = row.username_jira.split(' | ')\n",
    "            users = [user.lower() for user in users]\n",
    "            if username in users:\n",
    "                return row.id\n",
    "        else:\n",
    "            if row.username_jira.lower() == username:\n",
    "                return row.id\n",
    "\n",
    "    print('Não mapeado: {0}'.format(username))\n",
    "    return '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves unique user id based on git name\n",
    "def get_id_by_name_git(registers, name):\n",
    "    if pandas.isnull(name):\n",
    "        return '-1'\n",
    "\n",
    "    name = name.strip().lower()\n",
    "\n",
    "    names = registers.loc[registers.name_git.str.contains(str(name), na=False, case=False, regex=False)]\n",
    "\n",
    "    for index, row in names.iterrows():\n",
    "        if ', ' in row.name_git:\n",
    "            users = row.name_git.split(', ')\n",
    "            for user in users:\n",
    "                if name == user.strip().lower():\n",
    "                    return row.id\n",
    "        else:\n",
    "            if row.name_git.strip().lower() == name:\n",
    "                return row.id\n",
    "\n",
    "    print('Não mapeado: {0}'.format(name))\n",
    "    return '-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates new datasets based on the original, but using unique ids to identify contributors\n",
    "def replace_username_or_name_by_id():\n",
    "    registers = pandas.read_csv(PATH_GENERATED_FILES + \"final_list_of_contributors.csv\",\n",
    "                                index_col=None, header=0,\n",
    "                                delimiter=';')\n",
    "\n",
    "    snapshot_dataset = get_info_project_in_dataset(\"snapshot\")\n",
    "\n",
    "    commentlog_dataset = get_info_project_in_dataset(\"comment-log\")\n",
    "\n",
    "    changelog_dataset = get_info_project_in_dataset(\"changelog\")\n",
    "\n",
    "    commitlog_dataset = get_info_project_in_dataset(\"commit-log\")\n",
    "\n",
    "    for index, row in snapshot_dataset.iterrows():\n",
    "        snapshot_dataset.at[index, 'Reporter'] = get_id_by_username_jira(registers, row.Reporter)\n",
    "        snapshot_dataset.at[index, 'Assignee'] = get_id_by_username_jira(registers, row.Assignee)\n",
    "\n",
    "    snapshot_dataset.to_csv(PATH_GENERATED_FILES + 'new_snapshot_file.csv', sep=';', encoding='utf-8',\n",
    "                            index=False, na_rep='')\n",
    "    \n",
    "    for index, row in commentlog_dataset.iterrows():\n",
    "        commentlog_dataset.at[index, 'Author'] = get_id_by_username_jira(registers, row.Author)\n",
    "\n",
    "    commentlog_dataset.to_csv(PATH_GENERATED_FILES + 'new_comment_file.csv', sep=';', encoding='utf-8',\n",
    "                              index=False, na_rep='')\n",
    "    \n",
    "    for index, row in changelog_dataset.iterrows():\n",
    "        changelog_dataset.at[index, 'Author'] = get_id_by_username_jira(registers, row.Author)\n",
    "\n",
    "    changelog_dataset.to_csv(PATH_GENERATED_FILES + 'new_changelog_file.csv', sep=';', encoding='utf-8',\n",
    "                             index=False, na_rep='')\n",
    "\n",
    "    for index, row in commitlog_dataset.iterrows():\n",
    "\n",
    "        commitlog_dataset.at[index, 'Author'] = get_id_by_name_git(registers, row.Author)\n",
    "        commitlog_dataset.at[index, 'Committer'] = get_id_by_name_git(registers, row.Committer)\n",
    "\n",
    "    commitlog_dataset.to_csv(PATH_GENERATED_FILES + 'new_commit_file.csv', sep=';', encoding='utf-8',\n",
    "                             index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------- Main Flow ----------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation():\n",
    "    # 1 - retrieves the names of git (commit dataset) and jira (commentlog, changelog and snapshot)\n",
    "    print(\"**** Step 1 ****\")\n",
    "    jira_team_dataset, git_team_dataset = do_mine_contributors_names()\n",
    "\n",
    "    \"\"\" If you have already executed the line above once, you can choose to execute the lines below, \n",
    "        as it reduces processing time using data from files already generated.\n",
    "    \"\"\"\n",
    "    \"\"\"jira_team_dataset = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"jira-community-contributors-names.csv\", index_col=None,\n",
    "                                        header=0,\n",
    "                                        delimiter=';')\n",
    "\n",
    "    git_team_dataset = pandas.read_csv(PATH_SOCIAL_DATASET_FILES + \"git-community-contributors-names.csv\", index_col=None,\n",
    "                                       header=0,\n",
    "                                       delimiter=';')\"\"\"\n",
    "\n",
    "    # 2 - Handles JIRA data\n",
    "    print(\"**** Step 2 ****\")\n",
    "    \"\"\" \n",
    "        Previously, Apache provided the Jira API to download information from its users. However, this API is currently no \n",
    "        longer available. The records of the file used were obtained when it was still possible to retrieve this information\n",
    "        through the API.\n",
    "    \"\"\"\n",
    "    jira_team_dataset = group_by_name_usernames_of_jira()\n",
    "\n",
    "    print(\"**** Step 3 ****\")\n",
    "    # 3 - Handles Git data\n",
    "\n",
    "    official_committers_hadoop_dataset = union_pmc_and_committers_members_file()\n",
    "\n",
    "    union_hadoop_official_members_with_committers_of_dataset(git_team_dataset, official_committers_hadoop_dataset)\n",
    "\n",
    "    print(\"**** Step 4 ****\")\n",
    "\n",
    "    \"\"\"\n",
    "        Step made MANUALLY -> manual verification of the previously generated list, aiming to unify the records related to the \n",
    "        same contributor. Of those that were not associated with existing records, only one username could be found on the Internet\n",
    "        (Dongming Liang).\n",
    "        The file generated was 4-git_team_after_manual_map.csv\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"**** Step 5 ****\")\n",
    "    # 5 - Unify the listing of JIRA and Git records to generate unique IDs\n",
    "    join_contributors_info()\n",
    "\n",
    "    # 6 - Manual review required to verify the mappings performed.\n",
    "    print(\"**** Step 6 ****\")\n",
    "    final_processing_info_contributors()\n",
    "\n",
    "    # 7 - Generation of the new dataset using unique ids\n",
    "    print(\"**** Step 7 ****\")\n",
    "    replace_username_or_name_by_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Step 1 ****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Step 2 ****\n",
      "**** Step 3 ****\n",
      "**** Step 4 ****\n",
      "**** Step 5 ****\n",
      "**** Step 6 ****\n",
      "replacing \"Scott Chun-Yang Chen\" for \"Scott Chun-Yang Chen\"\n",
      "replacing \"Chris Nauroth, cnauroth\" for \"cnauroth\"\n",
      "replacing \"Vidura Mudalige\" for \"Vidura Mudalige\"\n",
      "replacing \"Márton Elek\" for \"Márton Elek\"\n",
      "replacing \"Owen O'Malley\" for \"Owen O'Malley\"\n",
      "replacing \"Akira Ajisaka\" for \"Akira Ajisaka\"\n",
      "replacing \"Devaraj K, Devarajulu K\" for \"Devaraj K, Devarajulu K\"\n",
      "replacing \"Bibin A Chundatt, bibinchundatt\" for \"Bibin A Chundatt, bibinchundatt\"\n",
      "replacing \"Bharat Viswanadham, bharat\" for \"Bharat Viswanadham, bharat\"\n",
      "replacing \"Arun C Murthy, Arun C. Murthy, Arun Murthy\" for \"Arun C Murthy, Arun C. Murthy, Arun Murthy\"\n",
      "replacing \"He Xiaoqiao\" for \"He Xiaoqiao\"\n",
      "replacing \"Vinod Kumar Vavilapalli, Vinod Kumar Vavilapalli (I am also known as @tshooter.), vinod kumar vavilapalli (i am also known as @tshooter.)\" for \"vinod kumar vavilapalli (i am also known as @tshooter.)\"\n",
      "replacing \"Billie Rinaldi\" for \"Billie Rinaldi\"\n",
      "replacing \"Anu Engineer\" for \"Anu Engineer\"\n",
      "replacing \"Rohith Sharma K S, rohithsharmaks\" for \"rohithsharmaks\"\n",
      "replacing \"Nanda kumar\" for \"Nanda kumar\"\n",
      "replacing \"Yi Liu, yliu\" for \"yliu\"\n",
      "replacing \"Sandy Ryza, sanford ryza\" for \"sanford ryza\"\n",
      "replacing \"Matthew Foley, mattf\" for \"mattf\"\n",
      "replacing \"Arpit Agarwal, arp\" for \"Arpit Agarwal, arp\"\n",
      "replacing \"Konstantin Boudnik\" for \"Konstantin Boudnik\"\n",
      "replacing \"Prabhu Joseph\" for \"Prabhu Joseph\"\n",
      "replacing \"Yufei Gu, yufei\" for \"yufei\"\n",
      "replacing \"Takanobu Asanuma\" for \"Takanobu Asanuma\"\n",
      "replacing \"Andrew Purtell\" for \"Andrew Purtell\"\n",
      "replacing \"Kai Zheng, drankye\" for \"drankye\"\n",
      "replacing \"Chris Douglas, Christopher Douglas\" for \"Chris Douglas, Christopher Douglas\"\n",
      "replacing \"Thomas Graves, tgraves\" for \"tgraves\"\n",
      "replacing \"Thomas Marquardt\" for \"Thomas Marquardt\"\n",
      "replacing \"Sidharta Seethana, sidharta s\" for \"sidharta s\"\n",
      "replacing \"Subru Krishnan\" for \"Subru Krishnan\"\n",
      "replacing \"Eric Payne, Eric E Payne\" for \"Eric Payne, Eric E Payne\"\n",
      "replacing \"Patrick Hunt\" for \"Patrick Hunt\"\n",
      "droping: Akira Ajisaka\n",
      "droping: Arun C Murthy, Arun C. Murthy\n",
      "droping: Anu Engineer\n",
      "droping: Arpit Agarwal\n",
      "droping: Bharat Viswanadham\n",
      "droping: Bibin A Chundatt\n",
      "droping: Billie Rinaldi\n",
      "droping: Chris Douglas\n",
      "droping: Konstantin Boudnik\n",
      "droping: Márton Elek\n",
      "droping: Eric Payne, Eric E Payne\n",
      "droping: He Xiaoqiao\n",
      "droping: Nanda kumar\n",
      "droping: Owen O'Malley\n",
      "droping: Patrick Hunt\n",
      "droping: Prabhu Joseph\n",
      "droping: Scott Chun-Yang Chen\n",
      "droping: Subru Krishnan\n",
      "droping: Takanobu Asanuma\n",
      "droping: Andrew Purtell\n",
      "droping: Christopher Douglas\n",
      "droping: Thomas Marquardt\n",
      "droping: Vidura Mudalige\n",
      "**** Step 7 ****\n"
     ]
    }
   ],
   "source": [
    "data_preparation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
